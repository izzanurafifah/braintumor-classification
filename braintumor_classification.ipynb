{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/izzanurafifah/braintumor-classification/blob/main/braintumor_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184f30d7-901d-4fef-bfb1-0c8a2abf3bab",
      "metadata": {
        "id": "184f30d7-901d-4fef-bfb1-0c8a2abf3bab"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "folder_yes = 'brain_tumor_dataset/yes/'\n",
        "folder_no = 'brain_tumor_dataset/no/'\n",
        "count = 1\n",
        "\n",
        "for filename in os.listdir(folder_yes):\n",
        "    source = folder_yes + filename\n",
        "    destination = folder_yes + \"Y_\" + str(count) + \".jpg\"\n",
        "    os.rename(source, destination)\n",
        "    count+=1\n",
        "print(\"All files in Yes folder have been renamed.\")\n",
        "\n",
        "for filename in os.listdir(folder_no):\n",
        "    source = folder_no + filename\n",
        "    destination = folder_no + \"N_\" + str(count) + \".jpg\"\n",
        "    os.rename(source, destination)\n",
        "    count+=1\n",
        "print(\"All files in No folder have been renamed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c1a915-4caf-422c-aece-1c4da304b3e4",
      "metadata": {
        "id": "e5c1a915-4caf-422c-aece-1c4da304b3e4"
      },
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tumorous = os.listdir('brain_tumor_dataset/yes/')\n",
        "totalY = len(tumorous)\n",
        "\n",
        "nontumorous = os.listdir('brain_tumor_dataset/no/')\n",
        "totalN = len(nontumorous)\n",
        "\n",
        "data = {'tumorous': totalY, 'nontumorous': totalN}\n",
        "\n",
        "xAxis = data.keys()\n",
        "yAxis = data.values()\n",
        "\n",
        "fig = plt.figure(figsize=(3,5))\n",
        "plt.bar(xAxis, yAxis)\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Number of Brain Tumor Images\")\n",
        "plt.title(\"Count of Brain Tumor Images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed24b14e-4db7-4779-9d7b-fa76bfae8fbb",
      "metadata": {
        "id": "ed24b14e-4db7-4779-9d7b-fa76bfae8fbb"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import cv2\n",
        "\n",
        "def augmented_data(file_dir, n_generated_samples, save_to_dir):\n",
        "    data_generated = ImageDataGenerator(rotation_range=10,\n",
        "                                       width_shift_range=0.1,\n",
        "                                       shear_range=0.1,\n",
        "                                       brightness_range=(0.3, 1.0),\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True,\n",
        "                                       fill_mode='nearest')\n",
        "    for filename in os.listdir(file_dir):\n",
        "        image = cv2.imread(file_dir + '/' + filename)\n",
        "        image = image.reshape((1,) + image.shape)\n",
        "        save_prefix = \"aug_\" + filename[:-4]\n",
        "        i=0\n",
        "        for batch in data_generated.flow(x = image, batch_size = 1, save_to_dir = save_to_dir, save_prefix = save_prefix, save_format=\"jpg\"):\n",
        "            i+=1\n",
        "            if i>n_generated_samples:\n",
        "                break\n",
        "\n",
        "augmented_data_path = 'augmented_data/'\n",
        "\n",
        "augmented_data(folder_yes, 6, augmented_data_path + 'yes')\n",
        "augmented_data(folder_no, 9, augmented_data_path + 'no')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42e2c1a7-e9dc-4a87-b80c-d3bc4d329756",
      "metadata": {
        "id": "42e2c1a7-e9dc-4a87-b80c-d3bc4d329756"
      },
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "tumorous = os.listdir(augmented_data_path + 'yes')\n",
        "totalY = len(tumorous)\n",
        "\n",
        "nontumorous = os.listdir(augmented_data_path + 'no')\n",
        "totalN = len(nontumorous)\n",
        "\n",
        "total = totalY + totalN\n",
        "\n",
        "perY = (totalY/total)*100\n",
        "perN = (totalN/total)*100\n",
        "\n",
        "print(f\"Number of samples: {total}\")\n",
        "print(f\"Number of positive samples in percentage: {perY:.2f}%\")\n",
        "print(f\"Number of negative samples in percentage: {perN:.2f}%\")\n",
        "\n",
        "data = {'tumorous': totalY, 'nontumorous': totalN}\n",
        "\n",
        "xAxis = data.keys()\n",
        "yAxis = data.values()\n",
        "\n",
        "fig = plt.figure(figsize=(3,5))\n",
        "plt.bar(xAxis, yAxis)\n",
        "plt.xlabel(\"Data\")\n",
        "plt.ylabel(\"Number of Brain Tumor Images\")\n",
        "plt.title(\"Count of Brain Tumor Images\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c1431a-b605-4b19-8f1d-3be7f7cb0f4e",
      "metadata": {
        "id": "77c1431a-b605-4b19-8f1d-3be7f7cb0f4e"
      },
      "outputs": [],
      "source": [
        "# Cropped Image\n",
        "\n",
        "import cv2\n",
        "\n",
        "def crop_brain_tumor(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    threshold = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    threshold = cv2.erode(threshold, None, iterations = 2)\n",
        "    threshold = cv2.dilate(threshold, None, iterations = 2)\n",
        "\n",
        "    contours, _ = cv2.findContours(threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    c = max(contours, key = cv2.contourArea)\n",
        "\n",
        "    extLeft = tuple(c[c[:,:,0].argmin()][0])\n",
        "    extRight = tuple(c[c[:,:,0].argmax()][0])\n",
        "    extTop = tuple(c[c[:,:,1].argmin()][0])\n",
        "    extBottom = tuple(c[c[:,:,1].argmax()][0])\n",
        "\n",
        "    new_image = image[extTop[1]:extBottom[1], extLeft[0]:extRight[0]]\n",
        "\n",
        "    # fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    # axes[0].imshow(image)\n",
        "    # axes[0].set_title(\"Original Image\")\n",
        "\n",
        "    # axes[1].imshow(new_image)\n",
        "    # axes[1].set_title(\"Cropped Image\")\n",
        "\n",
        "    # plt.show()\n",
        "\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769d7b45-7e80-4836-aa87-f8397ea87d4a",
      "metadata": {
        "id": "769d7b45-7e80-4836-aa87-f8397ea87d4a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_yes = 'augmented_data/yes/'\n",
        "folder_no = 'augmented_data/no/'\n",
        "\n",
        "for filename in os.listdir(folder_yes):\n",
        "    img = cv2.imread(folder_yes + filename)\n",
        "    img = crop_brain_tumor(img)\n",
        "    cv2.imwrite(folder_yes + filename, img)\n",
        "\n",
        "for filename in os.listdir(folder_no):\n",
        "    img = cv2.imread(folder_no + filename)\n",
        "    img = crop_brain_tumor(img)\n",
        "    cv2.imwrite(folder_no + filename, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995ec3ca-78f5-402a-994c-0cb163f86405",
      "metadata": {
        "id": "995ec3ca-78f5-402a-994c-0cb163f86405"
      },
      "outputs": [],
      "source": [
        "# Image Load\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def load_data(dir_list, image_size):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    image_width, image_height = image_size\n",
        "\n",
        "    for directory in dir_list:\n",
        "        for filename in os.listdir(directory):\n",
        "            image = cv2.imread(directory + '/' + filename)\n",
        "            image = crop_brain_tumor(image)\n",
        "            image = cv2.resize(image, (image_width, image_height), interpolation = cv2.INTER_CUBIC)\n",
        "            image = image/255.00\n",
        "            X.append(image)\n",
        "            if directory[-3:] == 'yes':\n",
        "                y.append(1)\n",
        "            else:\n",
        "                y.append(0)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    X,y = shuffle(X,y)\n",
        "    print(f\"Number of example is: {len(X)}\")\n",
        "    print(f\"X shape is: {X.shape}\")\n",
        "    print(f\"y shape is: {y.shape}\")\n",
        "\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aed57c5a-7646-4010-837b-754ddde70bfe",
      "metadata": {
        "id": "aed57c5a-7646-4010-837b-754ddde70bfe"
      },
      "outputs": [],
      "source": [
        "augmented_yes = augmented_data_path + 'yes'\n",
        "augmented_no = augmented_data_path + 'no'\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = (240, 240)\n",
        "\n",
        "X = load_data([augmented_yes, augmented_no], (IMAGE_WIDTH, IMAGE_HEIGHT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab714e1d-04e2-4c58-8add-9398100cd618",
      "metadata": {
        "id": "ab714e1d-04e2-4c58-8add-9398100cd618"
      },
      "outputs": [],
      "source": [
        "# Data Split (70% Train, 15% Test, 15% Validation)\n",
        "\n",
        "import shutil\n",
        "\n",
        "original_file_yes = 'augmented_data/yes/'\n",
        "train_yes = []\n",
        "for i in range(0,760):\n",
        "    train_yes.append(os.listdir(original_file_yes)[i])\n",
        "for filename in train_yes:\n",
        "    src = os.path.join(original_file_yes, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/train/tumorous/', filename)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "test_yes = []\n",
        "for i in range(760,923):\n",
        "    test_yes.append(os.listdir(original_file_yes)[i])\n",
        "for filename in test_yes:\n",
        "    src = os.path.join(original_file_yes, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/test/tumorous/', filename)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "validation_yes = []\n",
        "for i in range(923,1085):\n",
        "    validation_yes.append(os.listdir(original_file_yes)[i])\n",
        "for filename in validation_yes:\n",
        "    src = os.path.join(original_file_yes, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/validation/tumorous/', filename)\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a652bcd8-d48e-4c83-8acb-f695ad7f0b77",
      "metadata": {
        "id": "a652bcd8-d48e-4c83-8acb-f695ad7f0b77"
      },
      "outputs": [],
      "source": [
        "original_file_no = 'augmented_data/no/'\n",
        "train_no = []\n",
        "for i in range(0,686):\n",
        "    train_no.append(os.listdir(original_file_no)[i])\n",
        "for filename in train_no:\n",
        "    src = os.path.join(original_file_no, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/train/nontumorous/', filename)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "test_no = []\n",
        "for i in range(686,833):\n",
        "    test_no.append(os.listdir(original_file_no)[i])\n",
        "for filename in test_no:\n",
        "    src = os.path.join(original_file_no, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/test/nontumorous/', filename)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "validation_no = []\n",
        "for i in range(833,980):\n",
        "    validation_no.append(os.listdir(original_file_no)[i])\n",
        "for filename in validation_no:\n",
        "    src = os.path.join(original_file_no, filename)\n",
        "    dst = os.path.join('tumorous_and_nontumorous/validation/nontumorous/', filename)\n",
        "    shutil.copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01e23438-43f1-4b8e-bd9d-b48451633595",
      "metadata": {
        "id": "01e23438-43f1-4b8e-bd9d-b48451633595"
      },
      "outputs": [],
      "source": [
        "# Model Build\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                  horizontal_flip=0.4,\n",
        "                  vertical_flip=0.4,\n",
        "                  rotation_range=40,\n",
        "                  shear_range=0.2,\n",
        "                  width_shift_range=0.4,\n",
        "                  height_shift_range=0.4,\n",
        "                  fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataset(base_dir):\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        for dir_name in dirs:\n",
        "            if dir_name == \".ipynb_checkpoints\":\n",
        "                checkpoint_path = os.path.join(root, dir_name)\n",
        "                shutil.rmtree(checkpoint_path)\n",
        "                print(f\"Deleted: {checkpoint_path}\")\n",
        "\n",
        "dataset_base_dir = \"tumorous_and_nontumorous\"\n",
        "clean_dataset(dataset_base_dir)"
      ],
      "metadata": {
        "id": "FcuGFsFoVLPj"
      },
      "id": "FcuGFsFoVLPj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1795be7-8aa7-4d08-b05d-7ffd255f7d7a",
      "metadata": {
        "id": "c1795be7-8aa7-4d08-b05d-7ffd255f7d7a"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory('tumorous_and_nontumorous/train/', batch_size=32, target_size=(240,240), class_mode='categorical', shuffle=True, seed=42, color_mode='rgb')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory('tumorous_and_nontumorous/test/', batch_size=32, target_size=(240,240), class_mode='categorical', shuffle=True, seed=42, color_mode='rgb')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory('tumorous_and_nontumorous/validation/', batch_size=32, target_size=(240,240), class_mode='categorical', shuffle=True, seed=42, color_mode='rgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e2e60c-220b-4d50-83fa-b774d194a5e9",
      "metadata": {
        "id": "e1e2e60c-220b-4d50-83fa-b774d194a5e9"
      },
      "outputs": [],
      "source": [
        "class_labels = train_generator.class_indices\n",
        "class_name = {value: key for (key,value) in class_labels.items()}\n",
        "class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe8fbbd-7d0d-4d18-9baa-59bb16d6dcb4",
      "metadata": {
        "id": "2fe8fbbd-7d0d-4d18-9baa-59bb16d6dcb4"
      },
      "outputs": [],
      "source": [
        "base_model = VGG19(input_shape=(240, 240, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "x = base_model.output\n",
        "flat = Flatten()(x)\n",
        "\n",
        "class_1 = Dense(4608, activation='relu')(flat)\n",
        "drop_out = Dropout(0.2)(class_1)\n",
        "class_2 = Dense(1152, activation='relu')(drop_out)\n",
        "output = Dense(2, activation='softmax')(class_2)\n",
        "\n",
        "model_01 = Model(base_model.input, output)\n",
        "model_01.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d340724-1cfc-4f56-9915-475e770f04ad",
      "metadata": {
        "id": "5d340724-1cfc-4f56-9915-475e770f04ad"
      },
      "outputs": [],
      "source": [
        "# Callback\n",
        "\n",
        "filepath = 'model.keras'\n",
        "es = EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=4)\n",
        "cp = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
        "lrr = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55df99e8-9b7d-497e-b570-ab3a8331a1a2",
      "metadata": {
        "id": "55df99e8-9b7d-497e-b570-ab3a8331a1a2"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model_01.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee2fe04a-fce1-4904-9254-332274c717ec",
      "metadata": {
        "id": "ee2fe04a-fce1-4904-9254-332274c717ec"
      },
      "outputs": [],
      "source": [
        "history_01 = model_01.fit(train_generator, steps_per_epoch=10, epochs=20, callbacks=[es,cp,lrr], validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c285d0be-5895-4e56-966c-1bd6acdb2a24",
      "metadata": {
        "id": "c285d0be-5895-4e56-966c-1bd6acdb2a24"
      },
      "outputs": [],
      "source": [
        "# Plot Performance\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "fig.suptitle(\"Model Training (Frozen CNN)\", fontsize=12)\n",
        "max_epoch = len(history_01.history['accuracy'])+1\n",
        "epochs_list = list(range(1, max_epoch))\n",
        "\n",
        "ax1.plot(epochs_list, history_01.history['accuracy'], color='b', linestyle='-', label='Training Data')\n",
        "ax1.plot(epochs_list, history_01.history['val_accuracy'], color='r', linestyle='-', label='Validation Data')\n",
        "ax1.set_title('Training Accuracy', fontsize=12)\n",
        "ax1.set_xlabel('Epochs', fontsize=12)\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.legend(frameon=False, loc='lower center', ncol=2)\n",
        "\n",
        "ax2.plot(epochs_list, history_01.history['loss'], color='b', linestyle='-', label='Training Data')\n",
        "ax2.plot(epochs_list, history_01.history['val_loss'], color='r', linestyle='-', label='Validation Data')\n",
        "ax2.set_title('Training Loss', fontsize=12)\n",
        "ax2.set_xlabel('Epochs', fontsize=12)\n",
        "ax2.set_ylabel('Loss', fontsize=12)\n",
        "ax2.legend(frameon=False, loc='upper center', ncol=2)\n",
        "plt.savefig(\"training_frozencnn.jpeg\", format='jpeg', dpi=100, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fa500a-5a49-44ef-9dc3-83011b585f2a",
      "metadata": {
        "id": "84fa500a-5a49-44ef-9dc3-83011b585f2a"
      },
      "outputs": [],
      "source": [
        "model_01.save(filepath=\"model_weights/vgg19_model_01.keras\", overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c2ff8f-9106-4da9-91a6-46ccb8bc2a62",
      "metadata": {
        "id": "d9c2ff8f-9106-4da9-91a6-46ccb8bc2a62"
      },
      "outputs": [],
      "source": [
        "model_01.load_weights(\"model_weights/vgg19_model_01.keras\")\n",
        "vgg_val_eval_01 = model_01.evaluate(validation_generator)\n",
        "vgg_test_eval_01 = model_01.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe7472e5-65e5-4149-8dce-cae68bef38df",
      "metadata": {
        "id": "fe7472e5-65e5-4149-8dce-cae68bef38df"
      },
      "outputs": [],
      "source": [
        "print(f'Validation Loss: {vgg_val_eval_01[0]}')\n",
        "print(f'Validation Accuracy: {vgg_val_eval_01[1]}')\n",
        "print(f'Test Loss: {vgg_test_eval_01[0]}')\n",
        "print(f'Test Accuracy: {vgg_test_eval_01[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ebb318-22df-499d-833b-33b00526432e",
      "metadata": {
        "id": "b9ebb318-22df-499d-833b-33b00526432e"
      },
      "outputs": [],
      "source": [
        "filenames = test_generator.filenames\n",
        "nb_sample = len(filenames)\n",
        "\n",
        "vgg_prediction_01 = model_01.predict(test_generator, steps=nb_sample, verbose=1)\n",
        "y_pred = np.argmax(vgg_prediction_01, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d34cb7d-b061-4d49-9d3b-d18b00b8f1c5",
      "metadata": {
        "id": "6d34cb7d-b061-4d49-9d3b-d18b00b8f1c5"
      },
      "outputs": [],
      "source": [
        "# Incremental Unfreezing and Fine Tuning\n",
        "\n",
        "base_model = VGG19(include_top=False, input_shape=(240, 240, 3))\n",
        "base_model_layer_names = [layer.name for layer in base_model.layers]\n",
        "\n",
        "x = base_model.output\n",
        "flat = Flatten()(x)\n",
        "\n",
        "class_1 = Dense(4608, activation='relu')(flat)\n",
        "drop_out = Dropout(0.2)(class_1)\n",
        "class_2 = Dense(1152, activation='relu')(drop_out)\n",
        "output = Dense(2, activation='softmax')(class_2)\n",
        "\n",
        "model_02 = Model(base_model.inputs, output)\n",
        "model_02.load_weights('model_weights/vgg19_model_01.keras')\n",
        "\n",
        "set_trainable = False\n",
        "for layer in base_model.layers:\n",
        "    if layer.name in ['block5_conv4', 'block5_conv3']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print(model_02.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c3c8bb-6a99-4aae-b27c-f8377bb4aa31",
      "metadata": {
        "id": "08c3c8bb-6a99-4aae-b27c-f8377bb4aa31"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model_02.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49061437-55f8-4076-b689-a63eba88f8ff",
      "metadata": {
        "id": "49061437-55f8-4076-b689-a63eba88f8ff"
      },
      "outputs": [],
      "source": [
        "history_02 = model_02.fit(train_generator, steps_per_epoch=10, epochs=20, callbacks=[es,cp,lrr], validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dd0224-20ad-4091-9e3d-5376ef2b89c8",
      "metadata": {
        "id": "64dd0224-20ad-4091-9e3d-5376ef2b89c8"
      },
      "outputs": [],
      "source": [
        "# Plot Performance\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "fig.suptitle(\"Model Training (Frozen CNN)\", fontsize=12)\n",
        "max_epoch = len(history_02.history['accuracy'])+1\n",
        "epochs_list = list(range(1, max_epoch))\n",
        "\n",
        "ax1.plot(epochs_list, history_02.history['accuracy'], color='b', linestyle='-', label='Training Data')\n",
        "ax1.plot(epochs_list, history_02.history['val_accuracy'], color='r', linestyle='-', label='Validation Data')\n",
        "ax1.set_title('Training Accuracy', fontsize=12)\n",
        "ax1.set_xlabel('Epochs', fontsize=12)\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.legend(frameon=False, loc='lower center', ncol=2)\n",
        "\n",
        "ax2.plot(epochs_list, history_02.history['loss'], color='b', linestyle='-', label='Training Data')\n",
        "ax2.plot(epochs_list, history_02.history['val_loss'], color='r', linestyle='-', label='Validation Data')\n",
        "ax2.set_title('Training Loss', fontsize=12)\n",
        "ax2.set_xlabel('Epochs', fontsize=12)\n",
        "ax2.set_ylabel('Loss', fontsize=12)\n",
        "ax2.legend(frameon=False, loc='upper center', ncol=2)\n",
        "plt.savefig(\"training_frozencnn.jpeg\", format='jpeg', dpi=100, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52f9ac2-d837-4db5-9cc3-c3b86538fbb1",
      "metadata": {
        "id": "d52f9ac2-d837-4db5-9cc3-c3b86538fbb1"
      },
      "outputs": [],
      "source": [
        "model_02.save(filepath=\"model_weights/vgg19_model_02.keras\", overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a452c78e-5dc3-4a9f-abef-fb6ddb5dfda7",
      "metadata": {
        "id": "a452c78e-5dc3-4a9f-abef-fb6ddb5dfda7"
      },
      "outputs": [],
      "source": [
        "model_02.load_weights(\"model_weights/vgg19_model_02.keras\")\n",
        "vgg_val_eval_02 = model_02.evaluate(validation_generator)\n",
        "vgg_test_eval_02 = model_02.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d70576-bcdd-4d91-883e-8dd1f1f46a57",
      "metadata": {
        "id": "51d70576-bcdd-4d91-883e-8dd1f1f46a57"
      },
      "outputs": [],
      "source": [
        "# Unfreezing Entire Network\n",
        "\n",
        "base_model = VGG19(include_top=False, input_shape=(240, 240, 3))\n",
        "base_model_layer_names = [layer.name for layer in base_model.layers]\n",
        "\n",
        "x = base_model.output\n",
        "flat = Flatten()(x)\n",
        "\n",
        "class_1 = Dense(4608, activation='relu')(flat)\n",
        "drop_out = Dropout(0.2)(class_1)\n",
        "class_2 = Dense(1152, activation='relu')(drop_out)\n",
        "output = Dense(2, activation='softmax')(class_2)\n",
        "\n",
        "model_03 = Model(base_model.inputs, output)\n",
        "model_03.load_weights('model_weights/vgg19_model_02.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b99e889-a810-4965-88d4-4af2394a5714",
      "metadata": {
        "id": "7b99e889-a810-4965-88d4-4af2394a5714"
      },
      "outputs": [],
      "source": [
        "sgd = SGD(learning_rate=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model_03.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d367025-a8b3-47e6-873d-8539fbbd1d59",
      "metadata": {
        "id": "5d367025-a8b3-47e6-873d-8539fbbd1d59"
      },
      "outputs": [],
      "source": [
        "model_03.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eab7bb9-ba3b-4bcc-9c29-afdf920f04a2",
      "metadata": {
        "id": "8eab7bb9-ba3b-4bcc-9c29-afdf920f04a2"
      },
      "outputs": [],
      "source": [
        "history_03 = model_03.fit(train_generator, steps_per_epoch=10, epochs=20, callbacks=[es,cp,lrr], validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d7ee34e-e915-4bdc-808d-e2722c0a8239",
      "metadata": {
        "id": "6d7ee34e-e915-4bdc-808d-e2722c0a8239"
      },
      "outputs": [],
      "source": [
        "model_03.save(filepath=\"model_weights/vgg19_unfrozen.keras\", overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1758e1d0-6467-4787-94f3-2df261a772b9",
      "metadata": {
        "id": "1758e1d0-6467-4787-94f3-2df261a772b9"
      },
      "outputs": [],
      "source": [
        "model_03.load_weights(\"model_weights/vgg19_unfrozen.keras\")\n",
        "vgg_val_eval_03 = model_03.evaluate(validation_generator)\n",
        "vgg_test_eval_03 = model_03.evaluate(test_generator)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}